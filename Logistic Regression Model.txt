# Loading data and changing column names to more something more easily addresable
> data <- read.table(file.choose(), header = TRUE, sep = ",")
> colnames(data) <- c("Recency", "Frequency", "Monetary", "Time", "donatedMar07")

# Including library to make splitting the test and training data easier
> library(caTools)

# Making new dataset without Monetary attribute to make model without that attribute
> noblooddata <- subset(data, select = -c(Monetary))

# Splitting test and training data
> bloodspl <- sample.split(data$donatedMar07, SplitRatio = 0.8)
> nobloodspl <- sample.split(noblooddata$donatedMar07, SplitRatio = 0.8)
> bloodtrain <- subset(data, bloodspl == TRUE)
> bloodtest <- subset(data, bloodspl == FALSE)
> nobloodtrain <- subset(noblooddata, nobloodspl == TRUE)
> nobloodtest <- subset(noblooddata, nobloodspl == FALSE)

# Creating models
> nobloodmodel <- glm(donatedMar07 ~ ., data = nobloodtrain, family = binomial)
> bloodmodel <- glm(donatedMar07~., data = bloodtrain, family = binomial(link = "logit"))

# Using models to make predictions
> bloodtrain$predict <- predict(bloodmodel, newdata = bloodtrain, type = "response")
Warning message:
In predict.lm(object, newdata, se.fit, scale = 1, type = if (type ==  :
  prediction from a rank-deficient fit may be misleading
> bloodtest$predict <- predict(bloodmodel, newdata = bloodtest, type = "response")
Warning message:
In predict.lm(object, newdata, se.fit, scale = 1, type = if (type ==  :
  prediction from a rank-deficient fit may be misleading
> nobloodtrain$predict <- predict(nobloodmodel, newdata = nobloodtrain, type = "response")
> nobloodtest$predict <- predict(nobloodmodel, newdata = nobloodtest, type = "response")

# Evaluating prediction models with confusion matrix
> ctab.bloodtest <- table(predict = bloodtest$predict>0.5, donatedMar07=bloodtest$donatedMar07)
> ctab.nobloodtest <- table(predict = nobloodtest$predict>0.5, donatedMar07=nobloodtest$donatedMar07)
> ctab.bloodtest
       donatedMar07
predict   0   1
  FALSE 111  32
  TRUE    3   4
> ctab.nobloodtest
       donatedMar07
predict   0   1
  FALSE 111  30
  TRUE    3   6
> bloodprecision <- ctab.bloodtest[2,2] / sum(ctab.bloodtest[2,])
> nobloodprecision <- ctab.nobloodtest[2,2] / sum(ctab.nobloodtest[2,])
> bloodprecision
[1] 0.5714286
> nobloodprecision
[1] 0.6666667
> bloodrecall <- ctab.bloodtest[2,2] / sum(ctab.bloodtest[,2])
> nobloodrecall <- ctab.nobloodtest[2,2] / sum(ctab.nobloodtest[,2])
> bloodrecall
[1] 0.1111111
> nobloodrecall
[1] 0.1666667
> bloodenrich <- bloodprecision / mean(as.numeric(bloodtest$donatedMar07))
> nobloodenrich <- nobloodprecision / mean(as.numeric(nobloodtest$donatedMar07))
> bloodenrich
[1] 2.380952
> nobloodenrich
[1] 2.777778

# Model summaries
> summary(bloodmodel)

Call:
glm(formula = donatedMar07 ~ ., family = binomial(link = "logit"), 
    data = bloodtrain)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.4050  -0.7923  -0.5106  -0.2232   2.6080  

Coefficients: (1 not defined because of singularities)
             Estimate Std. Error z value Pr(>|z|)    
(Intercept) -0.468872   0.201437  -2.328  0.01993 *  
Recency     -0.094251   0.019114  -4.931 8.18e-07 ***
Frequency    0.129040   0.028037   4.603 4.17e-06 ***
Monetary           NA         NA      NA       NA    
Time        -0.022300   0.006608  -3.374  0.00074 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 655.57  on 597  degrees of freedom
Residual deviance: 573.14  on 594  degrees of freedom
AIC: 581.14

Number of Fisher Scoring iterations: 5

> summary(nobloodmodel)

Call:
glm(formula = donatedMar07 ~ ., family = binomial, data = nobloodtrain)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.3199  -0.8022  -0.4940  -0.1929   2.5382  

Coefficients:
             Estimate Std. Error z value Pr(>|z|)    
(Intercept) -0.408247   0.202065  -2.020  0.04334 *  
Recency     -0.106175   0.019369  -5.482 4.21e-08 ***
Frequency    0.116960   0.027274   4.288 1.80e-05 ***
Time        -0.019439   0.006392  -3.041  0.00236 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 655.57  on 597  degrees of freedom
Residual deviance: 569.98  on 594  degrees of freedom
AIC: 577.98

Number of Fisher Scoring iterations: 5

# Only looking for pseudo-r squared on the model without the Monetary attribute
# since the model that includes the attribute has shown to be not as good on several metrics
> df.null <- dim(nobloodtrain) [[1]] - 1
> df.model <- dim(nobloodtrain) [[1]] - length(nobloodmodel$coefficients)
> df.null
[1] 597
> df.model
[1] 594
> loglikelihood <- function(y, py) {sum(y * log(py) + (1-y)*log(1-py))}
> pnull <- mean(as.numeric(nobloodtrain$donatedMar07))
> null.dev <- -2*loglikelihood(as.numeric(nobloodtrain$donatedMar07), pnull)
> pred <- predict(nobloodmodel, newdata = nobloodtrain, type = "response")
> resid.dev <- -2*loglikelihood(as.numeric(nobloodtrain$donatedMar07), pred)
> delDev <- null.dev - resid.dev
> deldf <- df.null - df.model
> p <- pchisq(delDev, deldf, lower.tail = F)
> p
[1] 1.940714e-18
> pr2 <- 1 - (resid.dev/null.dev)
> print(pr2)
[1] 0.1305557

# If the model explains only about 13.05% of the deviance, then this is not a highly predictive model

# Function to normalize data
> normalize <- function(x) {return((x - min(x)) / (max(x) - min(x))) }
> data <- subset(data, select = -c(Monetary))
> data_n <- as.data.frame(lapply(data[,c(1,2,3,4)], normalize))

# Splitting test and training data
> set.seed(1234)
> spl <- sample.split(data_n$donatedMar07, SplitRatio = 0.8)
> train <- subset(data_n, spl == TRUE)
> test <- subset(data_n, spl == FALSE)
> attach(data_n)

# Creating model
> normmodel <- glm(donatedMar07 ~ ., data = train, family = binomial(link = "logit"))

# Using model to make prediction
> train$predict <- predict(normmodel, newdata = train, type = "response")
> test$predict <- predict(normmodel, newdata = test, type = "response")

# Evaluating prediction models with confusion matrix
> ctab.normtest <- table(predict = test$predict>0.5, donatedMar07 = test$donatedMar07)
> ctab.normtest
       donatedMar07
predict   0   1
  FALSE 111  32
  TRUE    3   4
> precision <- ctab.normtest[2,2] / sum(ctab.normtest[2,])
> precision
[1] 0.5714286
> recall <- ctab.normtest[2,2] / sum(ctab.normtest[,2])
> enrich <- precision / mean(as.numeric(test$donatedMar07))
> enrich
[1] 2.380952
> summary(normmodel)

Call:
glm(formula = donatedMar07 ~ ., family = binomial(link = "logit"), 
    data = train)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.4050  -0.7923  -0.5106  -0.2232   2.6080  

Coefficients:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)  -0.3844     0.1936  -1.986  0.04709 *  
Recency      -6.9746     1.4144  -4.931 8.18e-07 ***
Frequency     6.3229     1.3738   4.603 4.17e-06 ***
Time         -2.1408     0.6344  -3.374  0.00074 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 655.57  on 597  degrees of freedom
Residual deviance: 573.14  on 594  degrees of freedom
AIC: 581.14

Number of Fisher Scoring iterations: 5

# Pseudo-R sqaured of model
> df.null <- dim(train) [[1]] - 1
> df.model <- dim(train) [[1]] - length(normmodel$coefficients)
> df.null
[1] 597
> df.model
[1] 594
> pnull <- mean(as.numeric(train$donatedMar07))
> null.dev <- -2*loglikelihood(as.numeric(train$donatedMar07), pnull)
> pred <- predict(normmodel, newdata = train, type = "response")
> resid.dev <- -2*loglikelihood(as.numeric(train$donatedMar07), pred)
> delDev <- null.dev - resid.dev
> deldf <- df.null - df.model
> p <- pchisq(delDev, deldf, lower.tail = F)
> p
[1] 9.259681e-18
> pr2 <- 1 - (resid.dev/null.dev)
> print(pr2)
[1] 0.1257323

# This model explains even less of the deviance, at 12.57%, making this a less predictive model